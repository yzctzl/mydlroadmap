# **第一章**

# **引论**

人工智能（Artificial intelligence, AI）致力于构建能够模拟智能行为的系统。它涵盖了广泛的方法，包括基于逻辑、搜索和概率推理的方法。**机器学习**是人工智能的一个子集，它通过将数学模型与观测数据进行拟合来学习如何做出决策。这一领域经历了爆炸性的增长，如今几乎（不正确地）成为了“人工智能”一词的同义词。

**深度神经网络**（deep neural network），或简称**深度网络**（deep network），是机器学习模型的一种，而将这些模型与数据进行拟合的过程则被称为**深度学习**（deep learning）。在撰写本书时，深度网络已成为功能最强大、应用最广泛的机器学习模型，在日常生活中随处可见。例如，我们普遍使用自然语言处理算法将文本翻译成另一种语言，使用计算机视觉系统搜索包含特定物体的图片，或者通过语音识别接口与数字助理交谈。所有这些应用的核心驱动力都是深度学习。

顾名思义，本书旨在帮助该领域的新读者理解深度学习背后的原理。本书既不过于艰涩（没有理论证明），也不极度偏重实践（几乎没有代码）。其目标是阐释深度学习的根本思想；在阅读本书之后，读者将能够把深度学习的原理应用于那些尚无现成成功方案的新颖场景。

机器学习方法大致可以分为三个领域：监督学习、无监督学习和强化学习。在撰写本书时，这三个领域的前沿方法都依赖于深度学习（图 1.1）。本导论章节将从宏观层面介绍这三个领域，而本书的组织结构也大致遵循了这一分类。无论我们是否乐见，深度学习都注定将改变我们的世界，而这种改变并非全然是积极的。因此，本章还包含一个关于人工智能伦理的简要入门。最后，我们将就如何最有效地利用本书提出一些建议。

## **1.1 监督学习**

监督学习模型定义了从输入数据到输出预测的映射关系。在接下来的几节中，我们将讨论模型的输入、输出、模型本身，以及“训练”一个模型究竟意味着什么。

---
<center>

**图 1.1** 机器学习是人工智能的一个分支，它将数学模型与观测数据进行拟合。机器学习可以粗略地分为监督学习、无监督学习和强化学习。深度神经网络在这三个领域中都有所贡献。
</center>

---

### **1.1.1 回归与分类问题**

图 1.2 展示了几个回归和分类问题。在每个案例中，都有一个现实世界中有意义的输入（如一个句子、一段音频文件、一张图片等），这个输入被编码成一个数值向量。该向量构成模型的输入。模型将此输入映射到一个输出向量，然后这个输出向量被“翻译”回一个现实世界中有意义的预测。目前，我们先关注输入和输出，将模型视为一个接收数值向量并返回另一个数值向量的“黑箱”。

图 1.2a 中的模型根据房屋的面积和卧室数量等输入特征来预测其价格。这是一个**回归问题**（regression problem），因为模型返回的是一个连续的数值（而非一个类别归属）。

与此不同，图 1.2b 中的模型接收一个分子的化学结构作为输入，并同时预测其凝固点和沸点。这是一个**多元回归问题**（multivariate regression problem），因为它预测了不止一个数值。

图 1.2c 中的模型接收一个包含餐厅评论的文本字符串作为输入，并预测该评论是正面的还是负面的。这是一个**二元分类问题**（binary classification problem），因为模型试图将输入归入两个类别中的一个。其输出向量包含了输入分属各个类别的概率。

图 1.2d 和 1.2e 展示了**多类分类问题**（multiclass classification problems）。在这类问题中，模型将输入分配给 $N > 2$ 个类别中的一个。在第一个例子中，输入是一个音频文件，模型预测其所属的音乐流派。在第二个例子中，输入是一张图片，模型预测其中包含的对象。在每个案例中，模型都返回一个大小为 $N$ 的向量，其中包含了输入属于这 $N$ 个类别的概率。

---

<center>

**图 1.2 回归与分类问题** a) 这个**回归**模型接收一个描述房产特征的数值向量，并预测其价格。 b) 这个**多元回归**模型接收一个化学分子的结构，并预测其凝固点和沸点。 c) 这个**二元分类**模型接收一篇餐厅评论，并将其分类为正面或负面。 d) 这个**多类分类**问题将一段音频片段划分到 $N$ 种音乐流派中的一种。 e) 这是另一个多类分类问题，模型根据一张图片将其分类到 $N$ 种可能的物体中。
</center>

---

### **1.1.2 输入**

图 1.2 中的输入数据多种多样。在房价预测的例子中，输入是一个固定长度的向量，包含了描述房产的数值。这是一种**表格数据**（tabular data），因为它没有内部结构；如果我们改变输入值的顺序并重新构建一个模型，我们期望模型的预测结果保持不变。

相反，在餐厅评论的例子中，输入是一段文本。文本的长度可能因评论中的词语数量而异，并且在这里，输入的**顺序**至关重要；“my wife ate the chicken”（我妻子吃了鸡）与“the chicken ate my wife”（鸡吃了我妻子）的含义截然不同。在将文本送入模型之前，必须将其**编码**为数值形式。在此，我们使用一个大小为 10,000 的固定词汇表，并简单地将词语的索引连接起来。

对于音乐分类的例子，输入向量可能是固定大小的（比如一个 10 秒的片段），但维度非常高（即包含许多元素）。数字音频通常以 44.1 kHz 的频率采样，并用 16 位整数表示，因此一个十秒钟的音频片段就包含了 441,000 个整数。显然，监督学习模型必须能够处理大规模的输入。在图像分类的例子中，输入（由每个像素点的 RGB 值连接而成）同样是巨大的。此外，它还包含**空间结构**；一个像素点上下方的两个像素即使在输入向量中不相邻，它们之间也是密切相关的。

最后，考虑预测分子凝固点和沸点的模型的输入。一个分子可能包含不同数量的原子，这些原子可以通过不同的方式连接。在这种情况下，模型必须能同时处理分子的几何结构和其构成原子。

---
<center>

**图 1.3 机器学习模型** 模型表示了一系列关联输入（儿童年龄）与输出（儿童身高）的关系。具体的关系是通过**训练数据**（training data）（橙色点）来选择的。当我们训练模型时，我们在所有可能的关系中进行搜索，以找到一个能够很好地描述数据的关系。在这里，训练好的模型是青色的曲线，它可以用来计算任何年龄对应的身高。
</center>

---

### **1.1.3 机器学习模型**

到目前为止，我们一直将机器学习模型视为一个接收输入向量并返回输出向量的黑箱。但这个黑箱里究竟是什么呢？让我们以一个根据年龄预测儿童身高的模型为例（图 1.3）。机器学习模型是一个数学方程，它描述了平均身高随年龄变化的函数关系（图 1.3 中的青色曲线）。当我们将年龄输入这个方程时，它会返回相应的身高。例如，如果年龄是 10 岁，那么我们预测身高将是 139 厘米。

更准确地说，模型代表了**一系列**从输入到输出的映射方程（即一系列不同的青色曲线）。而具体的方程（曲线）是利用**训练数据**（即输入/输出对的样本）来选择的。在图 1.3 中，这些数据对由橙色点表示，我们可以看到模型（青色线）相当好地描述了这些数据。当我们谈论**训练**（training）或**拟合**（fitting）一个模型时，我们的意思是在所有可能的方程（可能的青色曲线）族中进行搜索，以找到那个能最准确描述训练数据的方程。

由此可见，图 1.2 中的模型都需要有标签的输入/输出对来进行训练。例如，音乐分类模型需要大量的音频片段，并且每个片段都由人类专家确定了其流派。这些输入/输出对在训练过程中扮演了教师或监督者的角色，这也正是**监督学习**（supervised learning）这个术语的由来。

### **1.1.4 深度神经网络**

本书关注的是深度神经网络，这是一种特别有用的机器学习模型。它们是一些数学方程，能够表示输入和输出之间极为广泛的关系族，并且在这个关系族中搜索以找到描述训练数据的关系也尤其容易。

深度神经网络可以处理非常巨大、长度可变且包含各种内部结构的输入。它们可以输出单个实数（回归）、多个数值（多元回归），或是在两个或多个类别上的概率（分别是二元和多类分类）。正如我们将在下一节看到的，它们的输出同样可以是巨大、长度可变且包含内部结构的。或许很难想象具备这些性质的方程，读者现在不妨姑且信之。

### **1.1.5 结构化输出**

图 1.4a 描绘了一个用于语义分割的多元二元分类模型。在这里，输入图像的每个像素都被分配一个二元标签，以指明它属于牛还是背景。图 1.4b 展示了一个多元回归模型，其输入是一张街景图片，输出是每个像素点的深度。在这两个例子中，输出都是高维且结构化的。然而，这种结构与输入紧密相关，这一点可以被利用；如果一个像素被标记为“牛”，那么一个具有相似 RGB 值的邻近像素很可能也拥有相同的标签。

图 1.4c-e 描绘了三个输出具有复杂结构但与输入关联不那么紧密的模型。图 1.4c 展示了一个模型，其输入是一个音频文件，输出是该文件中口语词汇的转录文本。图 1.4d 是一个翻译模型，输入为一段英文文本，输出为其法文翻译。图 1.4e 则是一项非常具有挑战性的任务，输入为一段描述性文字，模型必须生成一张与该描述相匹配的图像。

原则上，后三个任务可以在标准的监督学习框架下解决，但它们因两个原因而更具挑战性。首先，输出可能存在真正的**模糊性**；一个英文句子可以有多种有效的法文翻译，任何一个图片标题也可能对应多张合理的图片。其次，输出包含相当复杂的**结构**；并非所有词语的组合都能构成有效的英文和法文句子，也并非所有 RGB 值的集合都能构成一张可信的图像。除了学习映射关系，我们还必须尊重输出的“语法”。

幸运的是，这种“语法”可以在没有输出标签的情况下学习。例如，我们可以通过学习大量文本语料库的统计特性来了解如何构成有效的英文句子。这为本书的下一部分——无监督学习模型——建立了联系。

---
<center>

**图 1.4 具有结构化输出的监督学习任务**
a) 该语义分割模型将一张 RGB 图像映射为一张二值图像，其中每个像素点标明其属于背景还是牛（改编自 Noh et al., 2015）。
b) 该单目深度估计模型将一张 RGB 图像映射为一张输出图像，其中每个像素点代表其深度（改编自 Cordts et al., 2016）。
c) 该音频转录模型将一段音频样本映射为音频中所说词语的转录文本。
d) 该翻译模型将一个英文文本字符串映射为其法文翻译。
e) 该图像合成模型将一个标题文本映射为一张图像（示例来自 https://openai.com/dall-e-2/）。
在每个案例中，输出都具有复杂的内部结构或语法。在某些情况下，许多输出都可以与输入相兼容。
</center>

---

## **1.2 无监督学习**

在没有相应输出标签的情况下，从输入数据构建模型的过程被称为**无监督学习**（unsupervised learning）；由于没有输出标签，因此也就没有“监督”。其目标不是学习从输入到输出的映射，而是描述或理解数据的结构。与监督学习一样，数据可能具有截然不同的特性；它可以是离散的或连续的，低维的或高维的，长度固定或可变的。

### **1.2.1 生成模型**

本书重点关注**生成式无监督模型**（generative unsupervised models），这类模型学习合成与训练数据在统计上无法区分的新数据样本。一些生成模型明确地描述了输入数据的概率分布，然后通过从该分布中采样来生成新样本。另一些模型则只学习生成新样本的机制，而不明确描述其分布。

最先进的生成模型能够合成出极其逼真但又与训练样本不同的新样本。它们在生成图像（图 1.5）和文本（图 1.6）方面尤其成功。它们还可以在某些输出预先确定的约束下合成数据（称为**条件生成** (conditional generation)）。例如图像修复（图 1.7）和文本补全（图 1.8）。实际上，现代的文本生成模型功能强大，以至于它们看起来像是具有智能。给定一段文本后跟一个问题，模型通常能够通过生成文档最可能的续写来“填入”缺失的答案。然而，实际上，模型只了解语言的统计规律，并不理解其答案的意义。

---
<center>

**图 1.5 图像生成模型** 左图：两张图片由一个在猫的图片上训练的模型生成。这些并非真实的猫，而是从一个概率模型中抽取的样本。右图：两张图片由一个在建筑物的图片上训练的模型生成。改编自 Karras et al. (2020b)。
</center>

---
> 当我到达森林边缘时，月亮已经升起，透过树木的光线银白而寒冷。我打了个寒颤，虽然并不冷，但还是加快了脚步。我以前从未离村子这么远，也不知道会遇到什么。我已经走了好几个小时，又累又饿。我走得太匆忙，没想过要带任何食物，也没想过要带武器。我手无寸铁，独自一人在一个陌生的地方，不知道自己在做什么。
>
> 我已经走了很久，以至于完全失去了时间感，也不知道自己走了多远。我只知道我必须继续走下去。我必须找到她。我越来越近了。我能感觉到。她就在附近，而且遇到了麻烦。我必须找到她，帮助她，趁现在还来得及。
<center>

**图 1.6** 由文本数据的生成模型合成的短篇故事。该模型描述了一个为每个输出字符串分配概率的概率分布。从模型中采样会创建遵循训练数据（此处为短篇故事）统计特性的新字符串，但这些字符串是前所未见的。
</center>

---
<center>

**图 1.7 图像修复（Inpainting）** 在原始图像（左）中，男孩被金属缆绳遮挡。这些不需要的区域（中）被移除，生成模型在保持其余像素不变的约束下，合成了新的图像（右）。改编自 Saharia et al. (2022a)。
</center>

---
> 我在巴斯大学第一次讲课前有点紧张。教室里好像有几百个学生，他们看起来令人生畏。我走上讲台，正要开口说话，这时发生了一件奇怪的事。
>
> 突然，房间里充满了震耳欲聋的噪音，像一声巨吼。声音太大了，我什么也听不见，只能捂住耳朵。我看到学生们环顾四周，既困惑又害怕。然后，噪音来得快去得也快，房间又恢复了寂静。
>
> 我站在那里呆了一会儿，试图理解刚才发生的一切。然后我意识到学生们都盯着我，等我说话。我试图想些诙谐或聪明的话来说，但我的脑子一片空白。所以我只是说，“嗯，那真奇怪，”然后就开始了我的讲座。
<center>

**图 1.8 条件文本合成** 给定一段初始文本（黑色部分），文本生成模型可以通过合成“缺失”的字符串剩余部分来合理地延续该字符串。由 GPT3 生成（Brown et al., 2020）。
</center>

---
<center>

**图 1.9 人脸的变化** 人脸大约包含 42 块肌肉，因此，在相同光照条件下，描述同一个人面部表情的大部分变化，可能只需要 42 个数字就足够了。总的来说，图像、音乐和文本数据集都可以用比原始变量少得多的潜在变量来描述，尽管通常很难将这些潜在变量与特定的物理机制联系起来。图片来自 Dynamic FACES 数据库（Holland et al., 2019）。
</center>

---

### **1.2.2 潜变量**

一些（但非全部）生成模型利用了数据维度低于原始观测变量数量所暗示的事实。例如，有效且有意义的英文句子数量远小于随机抽取词语所能创造的字符串数量。同样，现实世界的图像只是通过为每个像素随机抽取红、绿、蓝（RGB）值所能创建的图像中的一个极小子集。这是因为图像是由物理过程生成的（见图 1.9）。

这就引出了一个想法，即我们可以用一组数量较少的底层**潜变量**（latent variables）来描述每个数据样本。在这里，深度学习的作用就是描述这些潜变量与数据之间的映射关系。潜变量通常被设计为具有简单的概率分布。因此，通过从这个简单的分布中采样，然后使用深度学习模型将样本映射到观测数据空间，我们就可以创建新的样本（图 1.10）。

这些模型带来了处理真实数据的新方法。例如，考虑找到支撑两个真实样本的潜变量。我们可以通过对它们的潜在表示进行插值，并将中间位置映射回数据空间，从而在两个样本之间进行插值（图 1.11）。

---
<center>

**图 1.10 潜变量** 许多生成模型使用一个深度学习模型来描述低维“潜”变量与观测到的高维数据之间的关系。根据设计，潜变量具有简单的概率分布。因此，可以通过从这个简单分布中对潜变量进行采样，然后使用深度学习模型将样本映射到观测数据空间，来生成新的样本。
</center>

---
<center>

**图 1.11 图像插值** 在每一行中，最左和最右的图像是真实的，中间的三张图像代表了由生成模型创建的一系列插值。支撑这些插值的生成模型已经学习到，所有图像都可以由一组潜在的底层变量创建。通过找到两个真实图像的这些变量，对其值进行插值，然后用这些中间变量创建新图像，我们可以生成既视觉上合理又融合了两个原始图像特征的中间结果。顶行改编自 Sauer et al. (2022)。底行改编自 Ramesh et al. (2022)。
</center>

---
<center>

**图 1.12** 根据标题“A teddy bear on a skateboard in Times Square”（一只泰迪熊在时代广场的滑板上）生成的多张图片。由 DALL-E-2 生成（Ramesh et al., 2022）。
</center>

---

### **1.2.3 连接监督学习与无监督学习**

带有潜变量的生成模型也有益于那些输出具有结构（图 1.4）的监督学习模型。例如，考虑学习预测与标题相对应的图像。与其直接将文本输入映射到图像，我们可以学习解释文本的潜变量与解释图像的潜变量之间的关系。

这样做有三个优势。首先，由于输入和输出都是低维的，我们可能只需要更少的文本/图像对来学习这种映射。其次，我们更有可能生成一张看起来合理的图像；潜变量的任何合理取值都应该能产生一个看起来合理的样本。第三，如果我们在这两组潜变量之间的映射或从潜变量到图像的映射中引入随机性，那么我们就可以生成多张都能被该标题很好地描述的图像（图 1.12）。

## **1.3 强化学习**

机器学习的最后一个领域是**强化学习**（reinforcement learning）。这个范式引入了**智能体**（agent）的概念，它生活在一个世界中，并在每个时间步执行特定的**动作**（actions）。这些动作会改变系统的**状态**（state），但不一定是以确定的方式。采取一个动作也可能产生**奖励**（rewards），而强化学习的目标是让智能体学会选择能够带来平均高回报的动作。

一个复杂之处在于，奖励可能在动作发生一段时间后才出现，因此将奖励与动作关联起来并非易事。这被称为**时序信用分配问题**（temporal credit assignment problem）。随着智能体的学习，它必须在**探索**（exploration）和**利用**（exploitation）已知知识之间进行权衡；也许智能体已经学会了如何获得适度的奖励；它应该遵循这个策略（利用已知），还是应该尝试不同的动作以期获得更好的结果（探索其他机会）？

### **1.3.1 两个例子**

考虑教一个类人机器**人行走**。机器人可以在给定的时间内执行有限数量的动作（移动各个关节），这些动作会改变世界的状态（它的姿态）。我们可能会通过让机器人在障碍赛道中达到检查点来奖励它。要到达每个检查点，它必须执行许多动作，而当奖励被接收时，哪些动作对此有贡献，哪些是无关的，并不清楚。这就是时序信用分配问题的一个例子。

第二个例子是学习**下棋**。同样，智能体在任何给定时间都有一组有效的动作（棋步）。然而，这些动作以一种非确定性的方式改变系统状态；对于任何一种选择，对手都可能以多种不同的方式回应。在这里，我们可以设置一个基于吃子的奖励结构，或者只在游戏结束时给予一次性的胜利奖励。在后一种情况下，时序信用分配问题变得极为突出；系统必须学会在它所下的众多棋步中，哪些是导致成功或失败的关键。

探索-利用的权衡在这两个例子中也很明显。机器人可能已经发现，它可以侧躺着用一条腿推动自己前进。这个策略能让机器人移动并获得奖励，但比最优解——用双腿平衡行走——要慢得多。因此，它面临一个选择：是利用它已经知道的（笨拙地在地板上滑动），还是探索动作空间（这可能带来更快的移动方式）。类似地，在下棋的例子中，智能体可能学会了一套合理的开局棋路。它应该利用这些知识，还是探索不同的开局顺序？

深度学习如何融入强化学习框架可能并不显而易见。有几种可能的方法，但其中一种技术是使用深度网络来构建一个从观测到的世界状态到动作的映射。这被称为**策略网络**（policy network）。在机器人的例子中，策略网络会学习一个从其传感器测量值到关节运动的映射。在下棋的例子中，网络会学习一个从当前棋盘状态到选择棋步的映射（图 1.13）。

---
<center>

**图 1.13 用于强化学习的策略网络** 将深度神经网络融入强化学习的一种方法是使用它们来定义一个从状态（此处为棋盘上的位置）到动作（可能的移动）的映射。这个映射被称为**策略**。
</center>

---

## **1.4 伦理**

在不讨论人工智能的伦理影响的情况下撰写这本书是不负责任的。这项强大的技术将像电力、内燃机、晶体管或互联网一样，在很大程度上改变世界。在医疗、设计、娱乐、交通、教育以及几乎所有商业领域的潜在利益是巨大的。然而，科学家和工程师们往往对他们工作的成果抱有不切实际的乐观态度，而潜在的危害也同样巨大。以下段落重点阐述了五个方面的问题。

**偏见与公平 (Bias and fairness):** 如果我们训练一个系统，根据历史数据来预测个人的薪资水平，那么这个系统将重现历史上的偏见；例如，它很可能会预测女性的薪水应该低于男性。一些此类案例已经成为国际新闻事件：一个用于超分辨率人脸图像的AI系统，会让非白人看起来更像白人；一个用于生成图像的系统，在被要求合成律师的图片时，只生成了男性的照片。草率地应用基于AI的算法决策，有可能固化或加剧现有的偏见。更多讨论请参见 Binns (2018)。

**可解释性 (Explainability):** 深度学习系统会做出决策，但我们通常不确切知道它们是如何以及基于什么信息做出决策的。它们可能非常庞大，我们无法通过检查来理解它们的工作原理。这催生了可解释性AI（explainable AI）这一子领域。一个取得了一定成功的领域是产生局部解释；我们无法解释整个系统，但可以对某个特定决策为何做出提供一个可解释的描述。然而，是否有可能构建对其用户乃至其创造者完全透明的复杂决策系统，目前仍然未知。更多信息请参见 Grennan et al. (2022)。

**武器化AI (Weaponizing AI):** 所有的重大技术都曾被直接或间接地应用于战争。可悲的是，暴力冲突似乎是人类行为中不可避免的一部分。AI可以说是迄今为止被构建的最强大的技术，并且毫无疑问将在军事领域得到广泛部署。事实上，这已经正在发生（Heikkilä, 2022）。

**权力集中 (Concentrating power):** 世界上最强大的公司之所以在人工智能领域投入巨资，并非出于改善人类福祉的仁慈之心。他们知道这些技术将为他们带来巨额利润。与任何先进技术一样，深度学习很可能将权力集中在少数控制它的组织手中。将目前由人类完成的工作自动化，将改变经济环境，并对技能较少的低薪工人的生计产生不成比例的影响。乐观主义者认为，工业革命期间也发生过类似的颠覆，并最终带来了更短的工作时间。但事实是，我们根本不知道AI的大规模应用会对社会产生什么影响（参见 David, 2015）。

**生存风险 (Existential risk):** 对人类主要的生存风险都源于技术。气候变化是由工业化驱动的。核武器源于物理学的研究。由于交通、农业和建筑领域的创新使得人口更庞大、更密集、更互联，大流行病的可能性更大，传播速度也更快。人工智能带来了新的生存风险。我们应该非常谨慎地构建比人类更强大、更具扩展性的系统。在最乐观的情况下，它将把巨大的权力交到所有者手中。在最悲观的情况下，我们将无法控制它，甚至无法理解它的动机（参见 Tegmark, 2018）。

这份清单远非详尽无遗。人工智能还可能助长监视、虚假信息传播、侵犯隐私、欺诈和金融市场操纵，而训练AI系统所需的能源也加剧了气候变化。此外，这些担忧并非凭空猜测；已经有许多伦理上可疑的AI应用实例（可查阅 Dao, 2021 的部分列表）。此外，互联网近期的历史表明，新技术会以意想不到的方式造成伤害。八九十年代的在线社区几乎无法预见到假新闻、垃圾邮件、网络骚扰、欺诈、网络霸凌、incel文化、政治操纵、人肉搜索、网络激进化和报复性色情内容的泛滥。

每个学习或研究（或撰写关于）AI的人都应该思考，科学家在多大程度上应对其技术的应用负责。我们应该考虑到，资本主义是AI发展的主要驱动力，而法律的进步和社会公益的部署很可能远远落后。我们应该反思，作为科学家和工程师，是否有可能控制这个领域的进展并减少潜在的危害。我们应该考虑我们准备为哪种类型的组织工作。他们减少AI潜在危害的承诺有多认真？他们仅仅是在进行“伦理洗白”以降低声誉风险，还是真的实施了机制来制止有伦理问题的项目？

鼓励所有读者进一步探究这些问题。网址 https://ethics-of-ai.mooc.fi/ 上的在线课程是一个有用的入门资源。如果您是一位使用本书教学的教授，鼓励您与学生一起提出这些问题。如果您是一名学生，而您的课程没有这样做，那么请游说您的教授来推动这件事。如果您在企业环境中部署或研究AI，鼓励您审视您雇主的价值观，并在其存在不足时帮助改变它们（或者离开）。

## **1.5 本书结构**

本书的结构遵循了本引论的结构。第 2-9 章将逐步介绍监督学习的流程。我们描述浅层和深度神经网络，并讨论如何训练它们，以及如何衡量和提升它们的性能。第 10-13 章描述了深度神经网络常见的架构变体，包括卷积网络、残差连接和 Transformer。这些架构被广泛应用于监督学习、无监督学习和强化学习中。

第 14-18 章使用深度神经网络来处理无监督学习。我们为四种现代深度生成模型各设一章：生成对抗网络、变分自编码器、归一化流和扩散模型。第 19 章是对深度强化学习的简要介绍。这个主题本身就足以写成一本书，所以这里的处理必然是浅尝辄止。然而，这一处理旨在为不熟悉该领域的读者提供一个良好的起点。

尽管本书以此为名，但深度学习的某些方面仍然知之甚少。第 20 章提出了一些基本问题。为什么深度网络如此容易训练？为什么它们的泛化能力这么好？为什么它们需要这么大？它们需要是“深”的吗？在此过程中，我们探索了一些意想不到的现象，如损失函数的结构、双重下降（double descent）、顿悟（grokking）和彩票假设（lottery tickets）。本书以第 21 章结束，该章讨论了伦理和深度学习。

## **1.6 其他书籍**

本书内容自成体系，但仅限于深度学习的范畴。它旨在成为《深度学习》（Goodfellow et al., 2016）的精神继承者，那是一本极好的资源，但未涵盖近期的进展。要更广泛地了解机器学习，最新、最全面的资源是《概率机器学习》（Murphy, 2022, 2023）。不过，《模式识别与机器学习》（Bishop, 2006）仍然是一本优秀且相关的书籍。

如果您喜欢这本书，那么我之前的著作《计算机视觉：模型、学习与推断》（Prince, 2012）仍然值得一读。其中一些部分已经过时，但它对概率论（包括贝叶斯方法）有详尽的介绍，并且对潜变量模型、计算机视觉几何、高斯过程和图模型有很好的入门介绍。它使用了与本书相同的符号体系，并且可以在线找到。关于图模型的详细论述可以在《概率图模型：原理与技术》（Koller & Friedman, 2009）中找到，而高斯过程则由《机器学习中的高斯过程》（Williams & Rasmussen, 2006）一书涵盖。

关于背景数学，请参考《机器学习的数学》（Deisenroth et al., 2020）。对于更侧重于编码的方法，请参考《动手学深度学习》（Zhang et al., 2023）。计算机视觉的最佳综述是《计算机视觉：算法与应用》（Szeliski, 2022）和《计算机视觉基础》（Torralba et al., 2024）。学习图神经网络的一个好的起点是《图表示学习》（Hamilton, 2020）。强化学习领域的权威著作是《强化学习导论》（Sutton & Barto, 2018）。一个好的入门资源是《深度强化学习基础》（Graesser & Keng, 2019）。

## **1.7 如何阅读本书**

本书余下的大多数章节都包含正文、注释部分和一组问题。正文部分旨在自成体系，无需参考章节的其他部分即可阅读。背景数学知识已尽可能地融入正文。然而，对于那些可能会分散主线论证的较宏大主题，相关背景材料会放在附录中，并在页边空白处提供参考。参考：**附录 A 符号**。本书中的大多数符号都是标准的。然而，有些约定使用得不那么广泛，建议读者在继续之前查阅附录 A。

正文部分包含了许多关于深度学习模型和结果的新颖插图和可视化。我努力为现有的思想提供新的解释，而不仅仅是整理他人的工作。深度学习是一个新兴领域，有时一些现象尚未被完全理解。我会尽力明确指出这种情况，以及何时我的解释应持谨慎态度。

参考文献仅在描述结果时才在正文章节中引用。相反，它们可以在章节末尾的注释部分找到。我通常在正文中不遵循历史先例；如果当前技术的某个早期版本不再有用，那么我就不会提及它。然而，该领域的历史发展在注释部分有所描述，并且希望能够公正地给予 credit。注释按段落组织，并为进一步阅读提供指引。它们应该能帮助读者在该子领域中定位自己，并理解它与机器学习其他部分的关系。注释部分的自含性不如正文。根据您的背景知识水平和兴趣，您可能会发现这些部分或多或少有用。

每一章都有一些相关的问题。它们在正文中应该被尝试的地方，在页边空白处被引用。正如乔治·波利亚（George Pólya）所指出的，“你看，数学不是一项旁观者的运动。”他是对的，我强烈建议您在阅读过程中尝试解决这些问题。在某些情况下，它们提供的见解将帮助您理解正文。答案在相关网站（http://udlbook.com）上提供的问题会用星号标出。此外，通过该网站还可以获得帮助您理解本书思想的 Python 笔记本，这些笔记本也在文本的页边空白处被引用。参考：**笔记本 1.1 背景数学**。实际上，如果您感觉自己的基础有些生疏，现在就通过该笔记本学习一下背景数学可能是值得的。

不幸的是，人工智能研究的步伐使得这本书不可避免地会成为一个持续进行中的工作。如果您发现有难以理解的部分、明显的遗漏或看似多余的章节，请通过相关网站与我联系。我们可以共同使下一版变得更好。