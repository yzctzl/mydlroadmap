好的，请看我的翻译和解答。

***

# 第十五章
# 生成对抗网络

**生成对抗网络 (Generative Adversarial Network)** 或简称 **GAN**，是一种旨在生成与一组训练样本无法区分的新样本的无监督模型。GANs 仅仅是创建新样本的机制；它们不构建所建模数据的概率分布，因此无法评估一个新数据点属于同一分布的概率。

在 GAN 中，主要的**生成器 (generator)** 网络通过将随机噪声映射到输出数据空间来创建样本。如果第二个**判别器 (discriminator)** 网络无法区分生成的样本和真实样本，那么这些样本就必须是看似合理的。如果这个网络能够分辨出差异，这就提供了一个可以反馈回去以提高样本质量的训练信号。这个想法很简单，但训练 GANs 很困难：学习算法可能不稳定，而且尽管 GANs 可能学会生成逼真的样本，但这并不意味着它们学会了生成**所有**可能的样本。

GANs 已被应用于多种类型的数据，包括音频、3D模型、文本、视频和图。然而，它们在图像领域取得了最大的成功，可以生成几乎与真实照片无法区分的样本。因此，本章的例子将集中于合成图像。

## 15.1 以判别为信号

我们的目标是生成新的样本 $\{\mathbf{x}_j^*\}$，这些样本的分布与一组真实训练数据 $\{\mathbf{x}_i\}$ 的分布相同。单个新样本 $\mathbf{x}_j^*$ 是通过 (i) 从一个简单的基础分布（例如，标准正态分布）中选择一个潜变量 $\mathbf{z}_j$，然后 (ii) 将该数据通过一个带有参数 $\boldsymbol{\theta}$ 的网络 $\mathbf{x}_j^* = g[\mathbf{z}_j, \boldsymbol{\theta}]$ 来生成的。这个网络被称为**生成器**。在学习过程中，目标是找到参数 $\hat{\boldsymbol{\theta}}$，使得样本 $\{\mathbf{x}_j^*\}$ 看起来与真实数据 $\{\mathbf{x}_i\}$ “相似”（见图14.2a）。

相似性可以通过多种方式定义，但 GAN 使用的原则是，生成的样本应该在统计上与真实数据无法区分。为此，引入了第二个带有参数 $\boldsymbol{\phi}$ 的网络 $f[\cdot, \boldsymbol{\phi}]$，称为**判别器**。这个网络的目标是将其输入分类为真实样本或生成样本。如果这个任务被证明是不可能的，那么生成的样本就与真实样本无法区分，我们就成功了。如果可能，判别器就提供了一个可以用来改进生成过程的信号。

图15.1阐释了这一机制。我们从一组真实的一维样本 $\{\mathbf{x}_i\}$ 开始。每个面板（青色箭头）中都显示了这十个样本的一个不同批次 $\{\mathbf{x}_i\}_{i=1}^{10}$。为了创建一个样本批次 $\{\mathbf{x}_j^*\}$，我们使用简单的生成器：

$$
\mathbf{x}_j^* = g[\mathbf{z}_j, \theta] = \mathbf{z}_j + \theta,
\tag{15.1}
$$

其中潜变量 $\{\mathbf{z}_j\}$ 来自标准正态分布，参数 $\theta$ 沿 x 轴平移生成的样本（图15.1）。

在初始化时，$\theta=3.0$，生成的样本（橙色箭头）位于真实样本（青色箭头）的左侧。判别器被训练来区分生成的样本和真实的样本（sigmoid曲线表示数据点是真实的估计概率）。在训练期间，生成器参数 $\theta$ 被操纵以增加其样本被分类为真实的概率。在这里，这意味着增加 $\theta$，以便样本向右移动，到达 sigmoid 曲线更高的地方。

我们交替更新判别器和生成器。图15.1b-c显示了这个过程的两次迭代。对数据进行分类逐渐变得更加困难，因此改变 $\theta$ 的动力变弱（即，sigmoid 曲线变得更平坦）。在过程结束时，没有办法区分这两组数据；判别器现在的性能是随机的，被丢弃，我们得到了一个能生成看似合理样本的生成器。

---

> **图 15.1 GAN 机制**
> a) 给定一个参数化函数（一个生成器）来合成样本（橙色箭头）和一批真实样本（青色箭头），我们训练一个判别器来区分真实样本和生成的样本（sigmoid曲线表示数据点是真实的估计概率）。b) 生成器通过修改其参数进行训练，使得判别器对其样本是合成的这一点的置信度降低（在这种情况下，通过将橙色样本向右移动）。然后更新判别器。c) 对生成器和判别器的交替更新，使得生成的样本变得与真实样本无法区分，改变生成器的动力（即sigmoid函数的斜率）也随之减弱。

---

### 15.1.1 GAN 损失函数

我们现在更精确地定义用于训练 GANs 的损失函数。判别器 $f[\mathbf{x}, \boldsymbol{\phi}]$ 接收输入 $\mathbf{x}$，拥有参数 $\boldsymbol{\phi}$，并返回一个标量，当它认为输入是真实样本时，该标量会更高。这是一个二元分类任务，因此我们调整二元交叉熵损失函数（5.4节），其原始形式为：

$$
\hat{\boldsymbol{\phi}} = \underset{\boldsymbol{\phi}}{\mathrm{argmin}} \left[ \sum_i -(1-y_i) \log[1-\text{sig}[f[\mathbf{x}_i, \boldsymbol{\phi}]]] - y_i \log[\text{sig}[f[\mathbf{x}_i, \boldsymbol{\phi}]]] \right],
\tag{15.2}
$$

其中 $y_i \in \{0, 1\}$ 是标签，$\text{sig}[\cdot]$ 是 logistic sigmoid 函数（图5.7）。
在这种情况下，我们假设真实样本 $\mathbf{x}$ 的标签为 $y=1$，生成的样本 $\mathbf{x}^*$ 的标签为 $y=0$，因此：

$$
\hat{\boldsymbol{\phi}} = \underset{\boldsymbol{\phi}}{\mathrm{argmin}} \left[ \sum_j -\log[1-\text{sig}[f[\mathbf{x}_j^*, \boldsymbol{\phi}]]] - \sum_i \log[\text{sig}[f[\mathbf{x}_i, \boldsymbol{\phi}]]] \right],
\tag{15.3}
$$

其中 $i$ 和 $j$ 分别索引真实样本和生成样本。
现在我们代入生成器的定义 $\mathbf{x}_j^* = g[\mathbf{z}_j, \boldsymbol{\theta}]$，并注意到我们必须相对于 $\boldsymbol{\theta}$ 进行最大化，因为我们希望生成的样本被错误分类（即，被认为是合成的似然性较低，或者负对数似然性较高）：

$$
\hat{\boldsymbol{\theta}} = \underset{\boldsymbol{\theta}}{\mathrm{argmax}} \ \underset{\boldsymbol{\phi}}{\mathrm{min}} \left[ \sum_j -\log[1-\text{sig}[f[g[\mathbf{z}_j, \boldsymbol{\theta}], \boldsymbol{\phi}]]] - \sum_i \log[\text{sig}[f[\mathbf{x}_i, \boldsymbol{\phi}]]] \right].
\tag{15.4}
$$

### 15.1.2 训练 GANs

方程15.4是一个比我们之前见过的更复杂的损失函数；判别器参数 $\boldsymbol{\phi}$ 被操纵以最小化损失函数，而生成器参数 $\boldsymbol{\theta}$ 被操纵以最大化损失函数。GAN 的训练被描述为一个**极小极大博弈 (minimax game)**；生成器试图找到新的方法来欺骗判别器，而判别器则反过来寻找新的方法来区分生成的样本和真实的样本。从技术上讲，解决方案是一个**纳什均衡 (Nash equilibrium)**——优化算法寻找一个同时是一个函数的最小值和另一个函数的最大值的位置。如果训练按计划进行，那么在收敛时，$g[\mathbf{z}, \boldsymbol{\theta}]$ 将从与数据相同的分布中抽取，而 $\text{sig}[f[\cdot, \boldsymbol{\phi}]]$ 的表现将是随机的（即，0.5）。

为了训练 GAN，我们可以将方程15.4分为两个损失函数：

$$
\begin{aligned}
L[\boldsymbol{\phi}] &= \sum_j -\log[1-\text{sig}[f[g[\mathbf{z}_j, \boldsymbol{\theta}], \boldsymbol{\phi}]]] - \sum_i \log[\text{sig}[f[\mathbf{x}_i, \boldsymbol{\phi}]]] \\
L[\boldsymbol{\theta}] &= \sum_j \log[1-\text{sig}[f[g[\mathbf{z}_j, \boldsymbol{\theta}], \boldsymbol{\phi}]]],
\end{aligned}
\tag{15.5}
$$

其中我们将第二个函数乘以-1以转换为最小化问题，并删除了不依赖于 $\boldsymbol{\theta}$ 的第二项。最小化第一个损失函数训练判别器。最小化第二个训练生成器。

在每一步，我们从基础分布中抽取一批潜变量 $\mathbf{z}_j$，并将它们通过生成器以创建样本 $\mathbf{x}_j^* = g[\mathbf{z}_j, \boldsymbol{\theta}]$。然后我们选择一批真实的训练样本 $\mathbf{x}_i$。给定这两个批次，我们现在可以在每个损失函数上执行一个或多个梯度下降步骤（图15.2）。

---

> **图 15.2 GAN 损失函数**
> 一个潜变量 $\mathbf{z}_j$ 从基础分布中抽取，并通过生成器来创建一个样本 $\mathbf{x}_j^*$。一批样本 $\{\mathbf{x}_j^*\}$ 和一批真实样本 $\{\mathbf{x}_i\}$ 被传递给判别器，判别器为每个样本分配一个为真的概率。判别器参数 $\boldsymbol{\phi}$ 被修改以对真实样本分配高概率，对生成样本分配低概率。生成器参数 $\boldsymbol{\theta}$ 被修改以“欺骗”判别器，使其为生成的样本分配高概率。

---

### 15.1.3 深度卷积 GAN

**深度卷积 GAN (Deep Convolutional GAN)** 或 **DCGAN** 是一种早期的专门用于生成图像的 GAN 架构（图15.3）。生成器 $g[\mathbf{z}, \boldsymbol{\theta}]$ 的输入是一个从均匀分布中采样的100维潜变量 $\mathbf{z}$。然后，这通过一个线性变换被映射到一个带有1024个通道的 $4 \times 4$ 空间表示。接下来是四个卷积层，每个都使用一个**分数步长卷积 (fractionally-strided convolution)**，使分辨率加倍（即，步长为0.5的卷积）。在最后一层，这个 $64 \times 64 \times 3$ 的信号通过一个 tanh 函数，以生成一个范围在 $[-1, 1]$ 内的图像 $\mathbf{x}^*$。判别器 $f[\cdot, \boldsymbol{\phi}]$ 是一个标准的卷积网络，其最终卷积层将大小减小到 $1 \times 1$，带有一个通道。这个单一的数字通过一个 sigmoid 函数 $\text{sig}[\cdot]$ 来创建输出概率。

训练后，判别器被丢弃。为了创建新样本，从基础分布中抽取潜变量 $\mathbf{z}$，并将其通过生成器。示例结果显示在图15.4中。

### 15.1.4 训练 GANs 的困难

理论上，GAN是相当直接的。然而，GANs是出了名的难以训练。例如，为了让DCGAN可靠地训练，必须 (i) 对上采样和下采样使用跨步卷积；(ii) 在生成器和判别器中都使用BatchNorm，但分别在最后一层和第一层除外；(iii) 在判别器中使用leaky ReLU激活函数（图3.13）；以及 (iv) 使用Adam优化器，但动量系数比通常的要低。这是不寻常的。大多数深度学习模型对这类选择相对鲁棒。

一个常见的失败模式是，生成器会生成看似合理的样本，但这些样本只代表了数据的一个子集（例如，对于人脸，它可能永远不会生成有胡子的人脸）。这被称为**模式丢失 (mode dropping)**。这种现象的一个极端版本可能发生，即生成器完全或大部分忽略潜变量 $\mathbf{z}$，并将所有样本都塌缩到一个或几个点上；这被称为**模式崩溃 (mode collapse)**（图15.5）。

---

> **图 15.3 DCGAN 架构**
> 在生成器中，一个100维的潜变量 $\mathbf{z}$ 从均匀分布中抽取，并通过线性变换映射到一个带有1024个通道的 $4 \times 4$ 表示。然后这通过一系列卷积层，逐渐对表示进行上采样并减少通道数。最后是一个tanh函数，将 $64 \times 64 \times 3$ 的表示映射到一个固定的范围，以便它可以代表一张图像。判别器由一个标准的卷积网络组成，它将输入分类为真实样本或生成样本。

> **图 15.4 从 DCGAN 模型合成的图像**
> a) 从在人脸数据集上训练的 DCGAN 中抽取的随机样本。b) 使用ImageNet数据库（见图10.15）的随机样本。c) 从LSUN场景理解数据集中抽取的随机样本。改编自 Radford et al. (2015)。

> **图 15.5 模式崩溃**
> 从一个在LSUN场景理解数据集上训练的GAN合成的图像，该GAN使用了一个与DCGAN具有相似参数和层数的MLP生成器。样本质量低，且许多是相似的。改编自 Arjovsky et al. (2017)。

---

## 15.2 提升稳定性

为了理解为什么GANs难以训练，有必要确切地理解损失函数代表了什么。

### 15.2.1 GAN损失函数分析

如果我们将方程15.5第一行中的两个和分别除以真实样本和生成样本的数量 $I, J$，那么损失函数可以写成期望的形式：

$$
L[\boldsymbol{\phi}] = -\frac{1}{J}\sum_{j=1}^J (\log[1-\text{sig}[f[\mathbf{x}_j^*, \boldsymbol{\phi}]]]) - \frac{1}{I}\sum_{i=1}^I (\log[\text{sig}[f[\mathbf{x}_i, \boldsymbol{\phi}]]]) \\
\approx -\mathbb{E}_{\mathbf{x}^*}[\log[1-\text{sig}[f[\mathbf{x}^*, \boldsymbol{\phi}]]]] - \mathbb{E}_{\mathbf{x}}[\log[\text{sig}[f[\mathbf{x}, \boldsymbol{\phi}]]]] \\
= -\int \text{Pr}(\mathbf{x}^*) \log[1-\text{sig}[f[\mathbf{x}^*, \boldsymbol{\phi}]]] d\mathbf{x}^* - \int \text{Pr}(\mathbf{x}) \log[\text{sig}[f[\mathbf{x}, \boldsymbol{\phi}]]] d\mathbf{x},
\tag{15.6}
$$

其中 $\text{Pr}(\mathbf{x}^*)$ 是生成样本上的概率分布，$\text{Pr}(\mathbf{x})$ 是真实样本上的真实概率分布。
当 $I=J$ 时，对于一个来源未知的样本 $\tilde{\mathbf{x}}$，最优的判别器是：

$$
\text{Pr}(\text{real}|\tilde{\mathbf{x}}) = \text{sig}[f[\tilde{\mathbf{x}}, \boldsymbol{\phi}]] = \frac{\text{Pr}(\tilde{\mathbf{x}}|\text{real})}{\text{Pr}(\tilde{\mathbf{x}}|\text{generated}) + \text{Pr}(\tilde{\mathbf{x}}|\text{real})} = \frac{\text{Pr}(\tilde{\mathbf{x}})}{\text{Pr}(\mathbf{x}^*) + \text{Pr}(\tilde{\mathbf{x}})},
\tag{15.7}
$$

在等式右边，我们根据生成的分布 $\text{Pr}(\mathbf{x}^*)$ 和真实分布 $\text{Pr}(\tilde{\mathbf{x}})$ 来评估 $\tilde{\mathbf{x}}$。代入方程15.6，我们得到：

$$
L[\boldsymbol{\phi}] = -\int \text{Pr}(\mathbf{x}^*) \log[1-\text{sig}[f[\mathbf{x}^*, \boldsymbol{\phi}]]] d\mathbf{x}^* - \int \text{Pr}(\mathbf{x}) \log[\text{sig}[f[\mathbf{x}, \boldsymbol{\phi}]]] d\mathbf{x} \\
= -\int \text{Pr}(\mathbf{x}^*) \log\left[1 - \frac{\text{Pr}(\mathbf{x}^*)}{\text{Pr}(\mathbf{x}^*) + \text{Pr}(\mathbf{x}^*)}\right] d\mathbf{x}^* - \int \text{Pr}(\mathbf{x}) \log\left[\frac{\text{Pr}(\mathbf{x})}{\text{Pr}(\mathbf{x}^*) + \text{Pr}(\mathbf{x})}\right] d\mathbf{x} \\
= -\int \text{Pr}(\mathbf{x}^*) \log\left[\frac{\text{Pr}(\mathbf{x}^*)}{\text{Pr}(\mathbf{x}^*) + \text{Pr}(\mathbf{x}^*)}\right] d\mathbf{x}^* - \int \text{Pr}(\mathbf{x}) \log\left[\frac{\text{Pr}(\mathbf{x})}{\text{Pr}(\mathbf{x}^*) + \text{Pr}(\mathbf{x})}\right] d\mathbf{x}.
\tag{15.8}
$$

忽略加法和乘法常数，这正是合成分布 $\text{Pr}(\mathbf{x}^*)$ 和真实分布 $\text{Pr}(\mathbf{x})$ 之间的**詹森-香农散度 (Jensen-Shannon divergence)**：参考：Problems 15.1-15.2, Appendix C.5.2 Jensen-Shannon divergence

$$
\begin{aligned}
D_{JS}[\text{Pr}(\mathbf{x}^*) || \text{Pr}(\mathbf{x})] &= \frac{1}{2}D_{KL}\left[\text{Pr}(\mathbf{x}^*) \left|\left| \frac{\text{Pr}(\mathbf{x}^*) + \text{Pr}(\mathbf{x})}{2}\right.\right.\right] + \frac{1}{2}D_{KL}\left[\text{Pr}(\mathbf{x}) \left|\left| \frac{\text{Pr}(\mathbf{x}^*) + \text{Pr}(\mathbf{x})}{2}\right.\right.\right] \\
&= \frac{1}{2} \int \text{Pr}(\mathbf{x}^*) \log\left[\frac{2\text{Pr}(\mathbf{x}^*)}{\text{Pr}(\mathbf{x}^*) + \text{Pr}(\mathbf{x})}\right] d\mathbf{x}^* + \frac{1}{2} \int \text{Pr}(\mathbf{x}) \log\left[\frac{2\text{Pr}(\mathbf{x})}{\text{Pr}(\mathbf{x}^*) + \text{Pr}(\mathbf{x})}\right] d\mathbf{x}.
\end{aligned}
\tag{15.9}
$$

其中 $D_{KL}[\cdot]$ 是**库尔贝克-莱布勒散度 (Kullback-Leibler divergence)**。参考：Appendix C.5.1 Kullback-Leibler divergence

第一项表示，如果样本密度 $\text{Pr}(\mathbf{x}^*)$ 高的地方，混合分布 $(\text{Pr}(\mathbf{x}^*)+\text{Pr}(\mathbf{x}))/2$ 的概率也高，那么距离就会小。换句话说，它惩罚了有样本 $\mathbf{x}^*$ 但没有真实样本 $\mathbf{x}$ 的区域；它强制要求**质量 (quality)**。第二项表示，如果真实密度 $\text{Pr}(\mathbf{x})$ 高的地方，混合分布 $(\text{Pr}(\mathbf{x}^*)+\text{Pr}(\mathbf{x}))/2$ 的概率也高，那么距离就会小。换句话说，它惩罚了有真实样本但没有生成样本的区域。它强制要求**覆盖度 (coverage)**。回到方程15.6，我们看到第二项不依赖于生成器，因此生成器不关心覆盖度；它乐于精确地生成可能样本的一个子集。这被认为是模式丢失的假定原因。

---

> **图 15.6 GAN损失函数的问题**
> 如果生成的样本（橙色箭头）很容易与真实样本（青色箭头）区分开，那么判别器（sigmoid曲线）在样本位置的斜率可能非常平缓；因此，更新生成器参数的梯度可能非常小。

---

### 15.2.2 梯度消失

在上一节中，我们看到当判别器最优时，损失函数最大化了生成样本和真实样本之间距离的一个度量。然而，使用这个概率分布之间的距离作为优化GANs的标准存在一个潜在问题。如果概率分布完全**不相交 (disjoint)**，这个距离是最大的，任何对生成器的微小改变都不会减少损失。当我们考虑原始公式时，可以看到同样的现象；如果判别器可以完美地分离生成的和真实的样本，那么对生成数据的微小改变不会改变分类得分（图15.6）。

不幸的是，生成的样本和真实样本的分布可能确实是不相交的；生成的样本位于一个大小为潜变量 $\mathbf{z}$ 的子空间中，而真实样本也由于创造数据的物理过程而位于一个低维子空间中（图1.9）。这些子空间之间可能很少或没有重叠，结果是梯度非常小或没有。

图15.7提供了支持这一假设的经验证据。如果DCGAN的生成器被冻结，并且判别器被反复更新以提高其分类性能，生成器的梯度会减小。简而言之，判别器的质量和生成器之间存在一个非常精细的平衡；如果判别器变得太好，生成器的训练更新就会减弱。

---

> **图 15.7 DCGAN生成器中的梯度消失**
> 生成器在1、10和25个周期后被冻结，判别器被进一步训练。生成器的梯度迅速减小（注意对数尺度）；如果判别器变得太准确，生成器的梯度就会消失。改编自 Arjovsky & Bottou (2017)。

---

### 15.2.3 瓦瑟斯坦距离

前面的章节表明 (i) GAN损失可以解释为概率分布之间的距离，以及 (ii) 当生成的样本太容易与真实样本区分时，这个距离的梯度变为零。显而易见的前进方向是选择一个具有更好属性的距离度量。
**瓦瑟斯坦距离 (Wasserstein distance)** 或（对于离散分布）**推土机距离 (earth mover's distance)** 是将一个分布的概率质量传输以创建另一个分布所需的功的数量。在这里，“功”被定义为质量乘以移动的距离。这立即听起来更有希望；即使分布不相交，瓦瑟斯坦距离也是良定义的，并且当它们彼此靠近时会平滑地减小。

### 15.2.4 离散分布的瓦瑟斯坦距离

瓦瑟斯坦距离对于离散分布最容易理解（图15.8）。考虑在 $K$ 个箱子上定义的分布 $\text{Pr}(x=i)$ 和 $q(x=j)$。假设将一个单位的质量从第一个分布的箱子 $i$ 移动到第二个分布的箱子 $j$ 有一个成本 $C_{ij}$；这个成本可能是索引之间的绝对差 $|i-j|$。移动的量构成了**传输计划 (transport plan)**，并存储在矩阵 $\mathbf{P}$ 中。

瓦瑟斯坦距离定义为：

$$
D_w[\text{Pr}(x) || q(x)] = \min_{\mathbf{P}} \left[ \sum_{i,j} P_{ij}|i-j| \right],
\tag{15.10}
$$

受以下约束：

$$
\begin{aligned}
\sum_j P_{ij} &= \text{Pr}(x=i) \\
\sum_i P_{ij} &= q(x=j) \\
P_{ij} &\ge 0
\end{aligned}
\quad
\begin{aligned}
&\text{Pr}(x) \text{的初始分布} \\
&q(x) \text{的初始分布} \\
&\text{非负质量}
\end{aligned}
\tag{15.11}
$$

换句话说，瓦瑟斯坦距离是一个受约束的最小化问题的解，该问题将一个分布的质量映射到另一个。这是不方便的，因为我们每次想要计算距离时都必须解决这个在元素 $P_{ij}$ 上的最小化问题。幸运的是，这是一个标准问题，对于小型方程系统很容易解决。它是一个**线性规划 (linear programming)** 问题，其**原始形式 (primal form)** 为：

---

**最小化** $\mathbf{c}^T \mathbf{p}$，
**使得** $\mathbf{Ap} = \mathbf{b}$
**且** $\mathbf{p} \ge \mathbf{0}$
**最大化** $\mathbf{b}^T \mathbf{f}$，
**使得** $\mathbf{A}^T \mathbf{f} \le \mathbf{c}$
**原始形式**
**对偶形式**

---

其中 $\mathbf{p}$ 包含决定移动质量的向量化元素 $P_{ij}$，$\mathbf{c}$ 包含距离，$\mathbf{Ap}=\mathbf{b}$ 包含初始分布约束，$\mathbf{p} \ge \mathbf{0}$ 确保移动的质量是非负的。¹

与所有线性规划问题一样，存在一个具有相同解的等价**对偶问题 (dual problem)**。在这里，我们相对于一个应用于初始分布的变量 $\mathbf{f}$ 进行最大化，受依赖于距离 $\mathbf{c}$ 的约束。这个对偶问题的解是：

$$
D_w[\text{Pr}(x) || q(x)] = \max_{\mathbf{f}} \left[\sum_i \text{Pr}(x=i)f_i - \sum_j q(x=j)f_j \right],
\tag{15.12}
$$

受约束于：

$$
|f_{i+1} - f_i| < 1.
\tag{15.13}
$$

换句话说，我们在一个新的变量集 $\{f_i\}$ 上进行优化，其中相邻的值的变化不能超过1。

---

> **图 15.8 瓦瑟斯坦距离或推土机距离**
> a) 考虑离散分布 $\text{Pr}(x=i)$。b) 我们希望移动概率质量以创建目标分布 $q(x=j)$。c) 传输计划 $\mathbf{P}$ 确定了将从 $i$ 移动到 $j$ 的质量。例如，青色高亮的方块 $p_{54}$ 指示了将从 $i=5$ 移动到 $j=4$ 的质量。传输计划的元素必须是非负的，对 $j$ 的总和必须是 $\text{Pr}(x=i)$，对 $i$ 的总和必须是 $q(x=j)$。因此 $\mathbf{P}$ 是一个联合概率分布。d) 元素 $i$ 和 $j$ 之间的距离矩阵。最优传输计划 $\mathbf{P}$ 最小化了 $\mathbf{P}$ 和距离矩阵的逐点乘积之和（称为瓦瑟斯坦距离）。因此，$\mathbf{P}$ 的元素倾向于靠近对角线，那里的距离成本最低。改编自 Hermann (2017)。

---

### 15.2.5 连续分布的瓦瑟斯坦距离

将这些结果转换回连续多维域，原始形式的等价物（方程15.10）是：

$$
D_w[\text{Pr}(\mathbf{x}), q(\mathbf{x})] = \min_{\pi[\cdot, \cdot]} \left[ \iint \pi(\mathbf{x}_1, \mathbf{x}_2) \cdot ||\mathbf{x}_1 - \mathbf{x}_2|| d\mathbf{x}_1 d\mathbf{x}_2 \right],
\tag{15.14}
$$

受类似于方程15.11的约束，关于代表从位置 $\mathbf{x}_1$ 移动到 $\mathbf{x}_2$ 的质量的传输计划 $\pi(\mathbf{x}_1, \mathbf{x}_2)$。对偶形式的等价物（方程15.12）是：

$$
D_w[\text{Pr}(\mathbf{x}), q(\mathbf{x})] = \max_{f[\mathbf{x}]} \left[ \int \text{Pr}(\mathbf{x})f[\mathbf{x}]d\mathbf{x} - \int q(\mathbf{x})f[\mathbf{x}]d\mathbf{x} \right],
\tag{15.15}
$$

受约束于函数 $f[\mathbf{x}]$ 的**利普希茨常数 (Lipschitz constant)** 小于1（即，函数的绝对梯度小于1）。参考：Problems 15.4-15.5, Appendix B.1.1 Lipschitz constant

### 15.2.6 瓦瑟斯坦GAN损失函数

在神经网络的背景下，我们通过优化神经网络 $f[\mathbf{x}, \boldsymbol{\phi}]$ 中的参数 $\boldsymbol{\phi}$ 来在函数 $f[\mathbf{x}]$ 的空间上进行最大化，并且我们使用生成的样本 $\mathbf{x}_j^*$ 和真实样本 $\mathbf{x}_i$ 来近似这些积分：

$$
L[\boldsymbol{\phi}] = \sum_j f[\mathbf{x}_j^*, \boldsymbol{\phi}] - \sum_i f[\mathbf{x}_i, \boldsymbol{\phi}] = \sum_j f[g[\mathbf{z}_j, \boldsymbol{\theta}], \boldsymbol{\phi}] - \sum_i f[\mathbf{x}_i, \boldsymbol{\phi}],
\tag{15.16}
$$

其中我们必须约束神经网络判别器 $f[\mathbf{x}_i, \boldsymbol{\phi}]$ 在每个位置 $\mathbf{x}$ 上的绝对梯度范数小于1：

$$
\left|\left| \frac{\partial f[\mathbf{x}, \boldsymbol{\phi}]}{\partial \mathbf{x}} \right|\right| < 1.
\tag{15.17}
$$

实现这一点的一种方法是将判别器的权重裁剪到一个小范围内（例如，$\pm 0.01$）。另一种方法是**梯度惩罚瓦瑟斯坦GAN (gradient penalty Wasserstein GAN)** 或 **WGAN-GP**，它增加一个正则化项，该项随着梯度范数偏离1而增加。

## 15.3 渐进式生长、小批量判别和截断

瓦瑟斯坦公式使GAN的训练更稳定。然而，生成高质量的图像还需要更多的机制。我们现在回顾**渐进式生长 (progressive growing)**、**小批量判别 (minibatch discrimination)** 和**截断 (truncation)**，它们都能提高输出质量。

在**渐进式生长**中（图15.9），我们首先训练一个GAN，它使用类似于DCGAN的架构合成 $4 \times 4$ 的图像。然后我们向生成器添加后续层，这些层对表示进行上采样并执行进一步的处理以创建 $8 \times 8$ 的图像。判别器也添加了额外的层，以便它可以接收更高分辨率的图像，并将它们分类为生成样本或真实样本。实际上，更高分辨率的层是随着时间逐渐“淡入”的；最初，更高分辨率的图像是前一个结果的上采样版本，通过残差连接传递，新的层逐渐接管。

**小批量判别**确保了样本具有足够的多样性，因此有助于防止模式崩溃。这可以通过计算合成和真实数据的小批量之间的特征统计来完成。这些可以被总结并作为一个特征图添加（通常是朝向判别器的末端）。这允许判别器向生成器发送一个信号，鼓励它在合成数据中包含与原始数据集相似的变化量。

改善生成结果的另一个技巧是**截断**（图15.10），其中在采样期间只选择概率高（即，接近均值）的潜变量 $\mathbf{z}$。这减少了样本的变化，但提高了它们的质量。仔细的归一化和正则化方案也提高了样本质量。使用这些方法的组合，GANs可以合成多样化且逼真的图像（图15.11）。平滑地在潜空间中移动有时也可以在两个合成图像之间产生逼真的插值（图15.12）。参考：Problem 15.6

---

> **图 15.9 渐进式生长**
> a) 生成器最初被训练来创建非常小的 $4 \times 4$ 图像，判别器则被训练来识别这些图像是合成的还是下采样的真实图像。b) 在这个低分辨率下训练终止后，后续的层被添加到生成器以生成 $8 \times 8$ 的图像。类似的层被添加到判别器以再次下采样。c) 这个过程继续创建 $16 \times 16$ 的图像，依此类推。通过这种方式，可以训练出一个能产生非常逼真的高分辨率图像的GAN。d) 从同一潜变量在不同阶段生成的、分辨率不断增加的图像。改编自 Wolf (2021)，使用 Karras et al. (2018) 的方法。

> **图 15.10 截断**
> GAN样本的质量可以通过拒绝那些来自均值超过 $\tau$ 个标准差的潜变量 $\mathbf{z}$ 的样本，来与多样性进行权衡。a) 如果这个阈值很大（$\tau=2.0$），样本在视觉上是多样的，但可能有缺陷。b-c) 随着这个阈值的减小，平均视觉质量提高，但多样性减少。d) 在一个非常小的阈值下，样本看起来几乎完全相同。通过明智地选择这个阈值，可以提高GAN结果的平均质量。改编自 Brock et al. (2019)。

> **图 15.11 组合方法**
> 当在CELEBA-HQ数据集上训练时，GANs可以生成逼真的人脸图像，当在LSUN类别上训练时，可以生成更复杂、多变的对象。改编自 Karras et al. (2018)。

> **图 15.12 遍历在LSUN汽车上训练的渐进式GAN的潜空间**
> 在潜空间中移动会产生平滑变化的汽车图像。这通常只在短轨迹上有效；最终，潜变量会移动到产生不切实际图像的地方。改编自 Karras et al. (2018)。

---

## 15.4 条件生成

GANs能产生逼真的图像，但没有指定它们的属性：我们无法选择人脸的头发颜色、种族或年龄，除非为每种特征组合训练单独的GANs。**条件生成 (Conditional generation)** 模型为我们提供了这种控制。

### 15.4.1 条件GAN

**条件GAN (conditional GAN)** 将一个属性向量 $\mathbf{c}$ 传递给生成器和判别器，现在它们被写为 $g[\mathbf{z}, \mathbf{c}, \boldsymbol{\theta}]$ 和 $f[\mathbf{x}, \mathbf{c}, \boldsymbol{\phi}]$。生成器的目标是将潜变量 $\mathbf{z}$ 转换为一个具有正确属性 $\mathbf{c}$ 的数据样本 $\mathbf{x}$。判别器的目标是区分 (i) 具有目标属性的生成样本 或 (ii) 具有真实属性的真实样本（图15.13a）。

对于生成器，属性 $\mathbf{c}$ 可以附加到潜向量 $\mathbf{z}$ 上。对于判别器，如果数据是一维的，它可以附加到输入上。如果数据包含图像，属性可以线性变换为一个二维表示，并作为额外通道附加到判别器输入或其一个中间隐藏层。

### 15.4.2 辅助分类器GAN

**辅助分类器GAN (auxiliary classifier GAN)** 或 **ACGAN** 通过要求判别器正确预测属性来简化条件生成（图15.13b）。对于具有 $C$ 个类别的离散属性，判别器接收真实/合成的图像作为输入，并有 $C+1$ 个输出；第一个通过一个sigmoid函数并预测样本是生成的还是真实的。其余的输出通过一个softmax函数来预测数据属于 $C$ 个类别中每一个的概率。用这种方法训练的网络可以从ImageNet合成多个类别（图15.14）。

### 15.4.3 InfoGAN

条件GAN和ACGAN都生成具有预定属性的样本。相比之下，**InfoGAN**（图15.13c）试图自动识别重要的属性。生成器接收一个由随机噪声变量 $\mathbf{z}$ 和随机属性变量 $\mathbf{c}$ 组成的向量。判别器既预测图像是真实的还是合成的，又估计属性变量。
其洞察力在于，可解释的现实世界特征应该是最容易预测的，因此将由属性变量 $\mathbf{c}$ 来表示。$\mathbf{c}$ 中的属性可以是离散的（将使用二元或多类别交叉熵损失）或连续的（将使用最小二乘损失）。离散变量识别数据中的类别，连续变量识别渐变的变化模式（图15.15）。

---

> **图 15.13 条件生成**
> a) 条件GAN的生成器还接收一个描述图像某些方面的属性向量 $\mathbf{c}$。像往常一样，判别器接收一个真实样本或一个生成样本，但现在它也接收属性向量；这鼓励样本既逼真又与属性兼容。b) 辅助分类器GAN (ACGAN) 的生成器接收一个离散的属性变量。判别器必须既 (i) 确定其输入是真实的还是合成的，又 (ii) 正确地识别类别。c) InfoGAN将潜变量分为噪声 $\mathbf{z}$ 和未指定的随机属性 $\mathbf{c}$。判别器必须区分其输入是否是真实的，并且还要重建这些属性。在实践中，这意味着变量 $\mathbf{c}$ 对应于具有现实世界解释的数据的显著方面（即，潜空间是解耦的）。

> **图 15.14 辅助分类器GAN**
> 生成器接收一个类别标签以及潜向量。判别器必须既识别数据点是否是真实的，又预测类别标签。这个模型在十个ImageNet类别上进行了训练。从左到右：生成的帝王蝶、金翅雀、雏菊、红脚鹬和灰鲸的例子。改编自 Odena et al. (2017)。

> **图 15.15 用于MNIST的InfoGAN**
> a) 来自MNIST数据库的训练样本，该数据库由 $28 \times 28$ 像素的手写数字图像组成。b) 第一个属性 $c_1$ 是具有10个类别的分类属性；每一列显示了用这些类别之一生成的样本。InfoGAN恢复了十个数字。属性向量 $c_2$ 和 $c_3$ 是连续的。c) 从左到右，每一列代表一个不同的 $c_2$ 值，同时保持其他潜变量不变。这个属性似乎对应于字符的方向。d) 第三个属性似乎对应于笔画的粗细。改编自 Chen et al. (2016b)。

---

## 15.5 图像翻译

尽管对抗性判别器最初是在GAN的背景下用于生成随机样本的，但它也可以用作一种先验，在将一个数据样本转换为另一个的任务中偏爱真实感。这最常用于图像，例如我们可能想将灰度图像转换为彩色图像，将噪声图像转换为干净图像，将模糊图像转换为清晰图像，或将草图转换为照片般逼真的图像。

本节讨论了三种使用不同数量手动标记的图像翻译模型。Pix2Pix模型使用前后配对进行训练。具有对抗性损失的模型使用前后配对进行主模型训练，但也在判别器中利用未配对的“后”图像。CycleGAN模型使用未配对的图像。

### 15.5.1 Pix2Pix

Pix2Pix模型（图15.16）是一个网络 $\mathbf{x} = g[\mathbf{c}, \boldsymbol{\theta}]$，它使用一个带有参数 $\boldsymbol{\theta}$ 的U-Net（图11.10）将一张图像 $\mathbf{c}$ 映射到另一种风格的图像 $\mathbf{x}$。一个典型的用例是着色，其中输入 $\mathbf{c}$ 是灰度的，输出 $g[\mathbf{c}, \boldsymbol{\theta}]$ 是彩色的。输出应该与输入相似，这是通过使用一个**内容损失 (content loss)** 来鼓励的，该损失惩罚输入 $\mathbf{c}$ 和真实输出 $\mathbf{x}$ 之间的 $\ell_1$ 范数 $||\mathbf{x} - g[\mathbf{c}, \boldsymbol{\theta}]||_1$。参考：Appendix B.3.2 $l_1$ norm
然而，输出图像也应该看起来像是输入的逼真转换。这是通过使用一个**对抗性判别器 (adversarial discriminator)** $f[\mathbf{c}, \mathbf{x}, \boldsymbol{\phi}]$ 来鼓励的，该判别器接收前后图像 $\mathbf{c}$ 和 $\mathbf{x}$。在每一步，判别器都试图区分一个真实的前后配对和一个前/合成配对。在这些可以被成功区分的程度上，一个反馈信号被提供来修改U-Net，使其输出更逼真。由于内容损失确保了大规模图像结构是正确的，判别器主要需要确保局部纹理是合理的。为此，**PatchGAN损失**是基于一个纯卷积分类器的。在最后一层，每个隐藏单元指示其感受野内的区域是真实的还是合成的。这些响应被平均以提供最终输出。

一种理解这个模型的方式是，它是一个条件GAN，其中U-Net是生成器，并以图像而不是标签为条件。然而，请注意，U-Net的输入不包括噪声，因此在传统意义上它并不是一个真正的“生成器”。有趣的是，原作者曾尝试在输入图像 $\mathbf{c}$ 之外向U-Net添加噪声 $\mathbf{z}$。然而，网络只是学会了忽略它。

### 15.5.2 对抗性损失

Pix2Pix模型的判别器试图区分图像翻译任务中的前后配对是否合理。这有一个缺点，即我们需要真实的前后配对才能利用判别器损失。幸运的是，有一种更简单的方法可以在监督学习的背景下利用对抗性判别器的力量，而不需要额外的标记训练数据。

**对抗性损失 (adversarial loss)** 会在一个判别器能够区分一个监督网络的输出和其输出域中的一个真实样本时增加一个惩罚。因此，监督模型会改变其预测以减少这个惩罚。这可以在整个输出的尺度上完成，也可以像在Pix2Pix算法中那样，在块的级别上完成。这有助于提高复杂结构化输出的**真实感 (realism)**。然而，它不一定会导致在原始损失函数方面更好的解决方案。

**超分辨率GAN (super-resolution GAN)** 或 **SRGAN** 使用了这种方法（图15.17）。主模型由一个带有残差连接的卷积网络组成，该网络接收一个低分辨率图像，并通过上采样层将其转换为高分辨率图像。该网络用三个损失进行训练。**内容损失**衡量输出和真实高分辨率图像之间的平方差。**VGG损失**或**感知损失 (perceptual loss)** 将合成和真实的输出通过VGG网络，并测量它们激活值之间的平方差。这鼓励图像在语义上与目标相似。最后，**对抗性损失**使用一个判别器，试图区分这是一个真实的高分辨率图像还是一个上采样的图像。这鼓励输出与真实样本无法区分。

### 15.5.3 CycleGAN

对抗性损失假设我们有用于主监督网络的标记的前后图像。**CycleGAN** 解决了我们有两组具有不同风格但没有匹配对的数据的情况。一个例子是将一张照片转换为莫奈的艺术风格。存在许多照片和许多莫奈的画作，但它们之间没有对应关系。CycleGAN利用了这样一个思想，即从一个方向（例如，照片到莫奈）转换图像，然后再转换回来，应该能恢复原始图像。

CycleGAN损失函数是三个损失的加权和（图15.18）。**内容损失**鼓励前后图像相似，并基于 $\ell_1$ 范数。**对抗性损失**使用一个判别器来鼓励输出看起来像目标域的真实样本。最后，**循环一致性损失 (cycle-consistency loss)** 鼓励映射是可逆的。在这里，两个模型被一起训练。一个从第一个域映射到第二个域，另一个则反向映射。如果翻译后的图像可以被成功地翻译回原始域中的图像，那么循环一致性损失就会很低。该模型结合了这三个损失来训练网络，以将图像从一种风格翻译到另一种，然后再翻译回来。

---

> **图 15.16 Pix2Pix 模型**
> a) 该模型使用U-Net（见图11.10）将输入图像翻译成不同风格的预测。在这种情况下，它将一张灰度图像映射到一个看似合理的彩色版本。U-Net用两个损失进行训练。首先，内容损失鼓励输出图像与输入图像具有相似的结构。其次，对抗性损失鼓励灰度/彩色图像对在这些图像的每个局部区域中都与真实配对无法区分。这个框架可以适应许多任务，包括 b) 将地图翻译成卫星图像，c) 将包的草图转换为照片般逼真的例子，d) 着色，以及 e) 将标签图转换为照片般逼真的建筑外墙。改编自 Isola et al. (2017)。

> **图 15.17 超分辨率生成对抗网络 (SRGAN)**
> a) 一个带有残差连接的卷积网络被训练来将图像的分辨率提高四倍。该模型有鼓励内容接近真实高分辨率图像的损失。然而，它也包括一个对抗性损失，该损失惩罚可以与真实高分辨率图像区分开的结果。b) 使用双三次插值上采样的图像。c) 使用SRGAN上采样的图像。d) 使用双三次插值上采样的图像。e) 使用SRGAN上采样的图像。改编自 Ledig et al. (2017)。

> **图 15.18 CycleGAN**
> 两个模型被同时训练。第一个 $c'=g[c_j, \boldsymbol{\theta}]$ 将第一种风格（马）的图像 $c$ 翻译成第二种风格（斑马）的图像 $c'$。第二个模型 $c=g'[c', \boldsymbol{\theta}']$ 学习相反的映射。循环一致性损失惩罚两个模型，如果它们不能成功地将图像转换到另一个域再转换回原始图像。此外，两个对抗性损失鼓励翻译后的图像看起来像目标域的真实例子（这里只显示了斑马的）。两个内容损失鼓励在每次映射前后图像的细节和布局相似（即，斑马与马处于相同的位置和姿势，并且背景相同，反之亦然）。改编自 Zhu et al. (2017)。

---

## 15.6 StyleGAN

**StyleGAN** 是一个更现代的GAN，它将数据集中的变化划分为有意义的组成部分，每个部分都由潜变量的一个子集控制。特别是，StyleGAN在不同尺度上控制输出图像，并将**风格 (style)** 与**噪声 (noise)** 分开。对于人脸图像，大规模的变化包括脸型和头部姿势，中等规模的变化包括面部特征的形状和细节，小规模的变化包括头发和皮肤颜色。风格部分代表了对人类有意义的图像方面，而噪声方面代表了不重要的变化，例如头发、胡茬、雀斑或皮肤毛孔的确切位置。

我们至今所见的GANs都是从一个从标准基础分布中抽取的潜变量 $\mathbf{z}$ 开始的。这通过一系列卷积层来产生输出图像。然而，潜变量输入到生成器可以 (i) 在架构的不同点引入，并且 (ii) 以不同的方式在这些点上修改当前的表示。StyleGAN明智地做出了这些选择，以控制尺度并将风格与噪声分开（图15.19）。

StyleGAN的主要生成分支始于一个学习到的常数 $4 \times 4$ 表示，带有512个通道。这通过一系列卷积层，逐渐对表示进行上采样以生成最终分辨率的图像。代表风格和噪声的两组随机潜变量在每个尺度上被引入；它们离输出越近，它们代表的细节就越精细。

代表噪声的潜变量是独立采样的**高斯向量 $\mathbf{z}_{n1}, \mathbf{z}_{n2}, \dots$**，并且在主生成流程中的每个卷积操作后被**加性注入**。它们与主表示在被添加的点上具有相同的空间大小，但被学习到的**逐通道缩放因子 $\boldsymbol{\psi}_1, \boldsymbol{\psi}_2, \dots$** 相乘，因此在每个通道中贡献的量不同。随着网络分辨率的增加，这种噪声在更精细的尺度上做出贡献。

代表风格的潜变量始于一个 $1 \times 1 \times 512$ 的噪声张量，它通过一个七层的全连接网络来创建一个中间变量 $\mathbf{w}$。这允许网络解耦风格的各个方面，以便 $\mathbf{w}$ 的每个维度可以代表一个独立的现实世界因素，如头部姿势或头发颜色。这个变量 $\mathbf{w}$ 被线性变换为一个 $2 \times 1 \times 512$ 的张量 $\mathbf{y}$，它被用来在噪声添加后设置主分支中跨空间位置的表示的**逐通道均值和方差**。这被称为**自适应实例归一化 (adaptive instance normalization)**（图11.14e）。一系列向量 $\mathbf{y}_1, \mathbf{y}_2, \dots$ 以这种方式在主分支的几个不同点被注入，因此相同的风格在不同的尺度上做出贡献。图15.20显示了在不同尺度上操纵风格和噪声向量的例子。

---

> **图 15.19 StyleGAN**
> 主流程（中心行）始于一个常数的、学习到的表示（灰色框）。这通过一系列卷积层并逐渐上采样以创建输出。噪声（顶行）通过周期性地添加带有逐通道缩放 $\boldsymbol{\psi}_\cdot$ 的高斯变量 $\mathbf{z}_\cdot$ 在不同尺度上被添加。高斯风格变量 $\mathbf{z}$ 通过一个全连接网络来创建中间变量 $\mathbf{w}$（底行）。这被用来在流程中的各个点设置每个通道的均值和方差。

> **图 15.20 StyleGAN 结果**
> 前四列显示了在不同尺度上风格的系统性变化。第五列显示了增加噪声幅度的效果。最后两列显示了在两个不同尺度上的不同噪声向量。

---

## 15.7 总结

GANs学习一个生成器网络，将随机噪声转换为与训练集无法区分的数据。为此，生成器是使用一个判别器网络进行训练的，该网络试图区分真实样本和生成样本。然后更新生成器，使其创建的数据被判别器识别为更“真实”。这个想法的原始公式有一个缺陷，即当样本是真实的还是生成的很容易确定时，训练信号很弱。这导致了**瓦瑟斯坦GAN (Wasserstein GAN)**，它提供了一个更一致的训练信号。

我们回顾了用于生成图像的卷积GANs以及一系列提高生成图像质量的技巧，包括渐进式生长、小批量判别和截断。**条件GAN (Conditional GAN)** 架构引入了一个辅助向量，允许对输出进行控制（例如，对象类别的选择）。> **图像翻译 (Image translation)** 任务以图像的形式保留了这种条件信息，但省去了随机噪声。GAN判别器现在作为一个额外的损失项，偏爱看起来“逼真”的图像。最后，我们描述了StyleGAN，它策略性地向生成器注入噪声，以在不同尺度上控制风格和噪声。
> 
### 注释

Goodfellow et al. (2014) 引入了生成对抗网络。早期的进展回顾可以在 Goodfellow (2016) 中找到。更近期的概述包括 Creswell et al. (2018) 和 Gui et al. (2021)。Park et al. (2021) 提供了对GAN模型的综述，重点是计算机视觉应用。Hindupur (2022) 维护了一个命名的GAN模型列表（在撰写本文时编号为501），从ABC-GAN (Susmelj et al., 2017) 一直到ZipNet-GAN (Zhang et al., 2017b)。Odena (2019) 列出了关于GANs的开放问题。

**数据**：GANs主要为图像数据开发。例子包括本章中介绍的深度卷积GAN (Radford et al., 2015)、渐进式GAN (Karras et al., 2018) 和 StyleGAN (Karras et al., 2019) 模型。因此，大多数GANs都基于卷积层，尽管最近，利用 Transformer 在生成器和判别器中捕捉长程相关性的GANs也已被开发出来（例如，SAGAN, Zhang et al., 2019b）。然而，GANs也被用来生成分子图 (De Cao & Kipf, 2018)、语音数据 (Saito et al., 2017; Donahue et al., 2018b; Kaneko & Kameoka, 2017; Fang et al., 2018)、脑电图数据 (Hartmann et al., 2018)、文本 (Lin et al., 2017a; Fedus et al., 2018)、音乐 (Mogren, 2016; Guimaraes et al., 2017; Yu et al., 2017)、3D模型 (Wu et al., 2016)、DNA (Killoran et al., 2017) 和视频数据 (Vondrick et al., 2016; Wang et al., 2018a)。

**GAN损失函数**：最初声称GANs在训练期间会收敛到纳什均衡。然而，最近的证据表明情况并非总是如此 (Farnia & Ozdaglar, 2020; Jin et al., 2020; Berard et al., 2019)。(Arjovsky et al., 2017; Metz et al., 2017; Qi, 2020) 发现原始的GAN损失函数不稳定，这导致了不同的公式。Mao et al. (2017) 引入了最小二乘GAN。对于某些参数选择，这隐式地最小化了皮尔逊 $\chi^2$ 散度。Nowozin et al. (2016) 认为詹森-香农散度是更广泛的f-散度家族的一个特例，并表明任何f-散度都可以用于训练GANs。Jolicoeur-Martineau (2019) 引入了相对论GAN，其中判别器估计一个真实数据样本比一个生成的样本更逼真的概率，而不是它是真实的绝对概率。Zhao et al. (2017a) 将GAN重新表述为一个通用的基于能量的框架，其中判别器是一个将低能量归因于真实数据而其他地方能量更高的函数。作为一个例子，他们使用一个自编码器并基于重构误差来确定能量。
Arjovsky & Bottou (2017) 分析了GANs中的梯度消失问题，这导致了瓦瑟斯坦GAN (Arjovsky et al., 2017)，它基于推土机距离/最优传输。瓦瑟斯坦公式要求判别器的利普希茨常数小于1；原始论文建议裁剪判别器中的权重，但后续工作施加了梯度惩罚 (Gulrajani et al., 2016) 或应用谱归一化 (Miyato et al., 2018) 来限制利普希茨常数。瓦瑟斯坦GAN的其他变体由 Wu et al. (2018a), Bellemare et al. (2017b), 和 Adler & Lunz (2018) 引入。Hermann (2017) 写了一篇优秀的博客文章，讨论了对偶性和瓦瑟斯坦GAN。有关最优传输的更多信息，请参阅 Peyré et al. (2019) 的书。Lucic et al. (2018) 提供了当时GAN损失函数的经验比较。

**训练GANs的技巧**：许多启发式方法提高了GANs训练的稳定性和最终结果的质量。Marchesi (2017) 首先使用了截断技巧（图15.10）来权衡GAN输出的可变性与它们的质量。Pieters & Wiering (2018) 和 Brock et al. (2019) 也提出了这一点，他们增加了一个正则化器，鼓励生成器中的权重矩阵是正交的。这意味着截断潜变量与截断输出方差有更密切的关系，并提高了样本质量。
其他技巧包括只使用来自前K个最逼真图像的梯度 (Sinha et al., 2020)，在判别器中使用标签平滑 (Salimans et al., 2016)，使用生成的图像历史而不是最新生成器产生的图像来更新判别器以避免模型“振荡” (Salimans et al., 2016)，以及向判别器输入添加噪声 (Arjovsky & Bottou, 2017)。Kurach et al. (2019) 提供了GANs中归一化和正则化的概述。Chintala et al. (2020) 提供了训练GANs的进一步建议。

**样本多样性**：最初的GAN论文 (Goodfellow et al., 2014) 认为，只要有足够的容量、训练样本和计算时间，GAN就可以学会最小化生成样本和真实分布之间的詹森-香农散度。然而，后续的工作对这是否在实践中发生提出了疑问。Arora et al. (2017) 提出，判别器的有限容量意味着即使在输出分布的变化有限时，GAN的训练目标也可以接近其最优值。Wu et al. (2017) 使用退火重要性采样近似了由GANs产生的分布的对数似然，并发现生成分布和真实分布之间存在不匹配。Arora & Zhang (2017) 要求人类观察者识别GAN样本中的（近）重复项，并从这些重复项的频率中推断图像的多样性。他们发现，对于DCGAN，用400个样本，重复出现的概率>50%；这意味着支持集的大小约为400,000，小于训练集。他们还表明，多样性随判别器大小的函数而增加。Bau et al. (2019) 采用了不同的方法，并研究了GANs无法生成的数据空间部分。

**增加多样性和防止模式崩溃**：缺乏多样性的极端情况是模式崩溃，即网络重复产生相同的图像 (Salimans et al., 2016)。这对于条件GANs是一个特别的问题，其中潜变量有时被完全忽略，输出仅取决于条件信息。Mao et al. (2019) 引入了一个正则化项来帮助防止条件GANs中的模式崩溃，该项最大化了生成的图像之间相对于相应潜变量的距离之比，因此鼓励了输出的多样性。旨在减少模式崩溃的其他工作包括VEEGAN (Srivastava et al., 2017)，它引入了一个重构网络，将生成的图像映射回原始噪声，因此不鼓励从噪声到图像的多对一映射。
Salimans et al. (2016) 建议跨小批量计算统计数据，并使用判别器来确保这些与真实图像批次的统计数据无法区分。这被称为**小批量判别 (mini-batch discrimination)**，并通过在判别器末端附近添加一个层来实现，该层为每个图像学习一个捕获批次统计的张量。Karras et al. (2018) 将此简化，他们为每个空间位置的每个特征计算了一个标准差，跨小批量。然后他们在空间位置和特征上进行平均以获得一个单一的估计。这被复制以获得一个单一的特征图，该特征图被附加到判别器网络末端附近的一层。Lin et al. (2018) 将连接的（真实的或生成的）样本传递给判别器，并提供了关于向判别器呈现多个样本如何增加多样性的理论分析。MAD-GAN (Ghosh et al., 2018) 通过使用多个生成器并要求单个判别器识别哪个生成器创建了样本，来增加GAN样本的多样性，从而提供一个信号来帮助推动生成器创建彼此不同的样本。

**多尺度 (Multiple scales)**：Wang et al. (2018b) 在不同尺度上使用多个判别器，以帮助确保所有频段的图像质量都很高。其他工作在不同分辨率下定义了生成器和判别器 (Denton et al., 2015; Zhang et al., 2017d; Huang et al., 2017c)。Karras et al. (2018) 引入了渐进式生长方法（图15.9），它在训练上更简单、更快。

**StyleGAN**：Karras et al. (2019) 引入了StyleGAN框架（15.6节）。在后续的工作中 (Karras et al., 2020b)，他们通过 (i) 重新设计生成器中的归一化层以移除“水滴”伪影和 (ii) 通过改变渐进式生长框架来减少精细细节不遵循粗糙细节的伪影，从而提高了生成图像的质量。进一步的改进包括开发用有限数据训练GANs的方法 (Karras et al., 2020a) 和修复混叠伪影 (Karras et al., 2021)。大量工作发现并操纵StyleGAN中的潜变量以编辑图像 (e.g., Abdal et al., 2021; Collins et al., 2020; Härkönen et al., 2020; Patashnik et al., 2021; Shen et al., 2020b; Tewari et al., 2020; Wu et al., 2021; Roich et al., 2022)。

**条件GANs**：条件GAN由 Mirza & Osindero (2014) 开发，辅助分类器GAN由 Odena et al. (2017) 开发，InfoGAN由 Chen et al. (2016b) 开发。这些模型的判别器通常将条件信息附加到判别器输入 (Mirza & Osindero, 2014; Denton et al., 2015; Saito et al., 2017) 或判别器中的一个中间隐藏层 (Reed et al., 2016a; Zhang et al., 2017d; Perarnau et al., 2016)。然而，Miyato & Koyama (2018) 实验了将嵌入的条件信息与判别器的一层取内积，其动机是类别信息在底层概率模型中的作用。由GANs生成的图像已分别以类别 (Odena et al., 2017)、输入文本 (Reed et al., 2016a; Zhang et al., 2017d)、属性 (Yan et al., 2016; Donahue et al., 2018a; Xiao et al., 2018b)、边界框和关键点 (Reed et al., 2016b) 和图像 (Isola et al., 2017) 为条件。

> **图像翻译 (Image translation)**：Isola et al. (2017) 开发了Pix2Pix算法（图15.16），一个具有更高分辨率结果的类似系统随后由 Wang et al. (2018b) 开发。StarGAN (Choi et al., 2018) 使用单个模型在多个域之间执行图像到图像的翻译。循环一致性损失的思想由 Zhou et al. (2016b) 在DiscoGAN中和 Zhu et al. (2017) 在CycleGAN中引入（图15.18）。
> 
**对抗性损失 (Adversarial loss)**：在许多图像翻译任务中，没有“生成器”；这些可以被认为是带有鼓励真实感的对抗性损失的监督学习任务。Ledig et al. (2017) 的超分辨率算法是这方面的一个很好的例子（图15.17）。Esser et al. (2021) 使用了带有对抗性损失的自编码器。这个网络接收一张图像，减小表示大小以创建一个“瓶颈”，然后从这个缩减的数据空间重建图像。在实践中，该架构类似于编码器-解码器网络（例如，图10.19）。训练后，自编码器重现了既接近图像又看起来高度逼真的东西。他们对自编码器的瓶颈进行矢量量化（离散化），然后使用一个 Transformer 解码器学习离散变量上的一个概率分布。通过从这个 Transformer 解码器中采样，他们可以产生极其庞大且高质量的图像。

**反转GANs (Inverting GANs)**：编辑真实图像的一种方法是将它们投影到潜空间，操纵潜变量，然后将它们重新投影到图像空间。这个过程被称为**再合成 (resynthesis)**。不幸的是，GANs只从潜变量映射到观测数据，反之则不然。这导致了反转GANs的方法（即，找到与观测图像尽可能接近对应的潜变量）。这些方法分为两类。第一类学习一个反向映射的网络 (Donahue et al., 2018b; Luo et al., 2017a; Perarnau et al., 2016; Dumoulin et al., 2017; Guan et al., 2020)。这被称为**编码器**。第二种方法是从某个潜变量 $\mathbf{z}$ 开始，并优化它直到它尽可能地重建图像 (Creswell & Bharath, 2018; Karras et al., 2020b; Abdal et al., 2019; Lipton & Tripathi, 2017)。Zhu et al. (2020a) 结合了这两种方法。
对于StyleGAN的反转特别有兴趣，因为它能产生出色的结果，并能在不同尺度上控制图像。不幸的是，Abdal et al. (2020) 表明，没有伪影地反转StyleGAN是不可能的，并建议反转到一个扩展的风格空间，而 Richardson et al. (2021) 训练了一个能可靠地映射到这个空间的编码器。即使在反转到扩展空间后，编辑域外图像可能仍然效果不佳。Roich et al. (2022) 通过微调StyleGAN的生成器来解决这个问题，使其能精确地重建图像，并表明结果可以被很好地编辑。他们还添加了额外的项来精确地重建附近的点，以便修改是局部的。这种技术被称为**关键枢轴调优 (pivotal tuning)**。GAN反转技术的综述可以在 Xia et al. (2022) 中找到。

**用GANs编辑图像 (Editing images with GANs)**：iGAN (Zhu et al., 2016) 允许用户通过涂鸦或扭曲现有图像的一部分来进行交互式编辑。该工具然后调整输出图像以既逼真又符合这些新的约束。它通过找到一个能产生与编辑后图像相似并遵守任何添加线条的边缘图的潜向量来实现这一点。通常还会添加一个掩码，以便只改变靠近编辑的图像部分。EditGAN (Ling et al., 2021) 联合建模图像及其语义分割掩码，并允许对该掩码进行编辑。

---

***

### 习题

**问题 15.1** 当 $\text{Pr}(\mathbf{x}^*) = \text{Pr}(\mathbf{x})$ 时，方程15.9中的损失会是多少？

**思路与解答：**

当两个分布相同时，$\text{Pr}(\mathbf{x}^*) = \text{Pr}(\mathbf{x})$。
詹森-香农散度 $D_{JS}[P||Q]$ 衡量两个分布的相似性。如果两个分布完全相同，它们的JS散度为0。
$D_{KL}[P||P] = \int P(x) \log\frac{P(x)}{P(x)} dx = \int P(x) \log(1) dx = 0$。
代入方程15.9，两个KL散度项都为0，因此 $D_{JS} = 0$。
所以，损失为 **0**。

**问题 15.2*** 写一个方程，关联方程15.8中的损失 $L$ 和方程15.9中的詹森-香农散度 $D_{JS}[\text{Pr}(\mathbf{x}^*)||\text{Pr}(\mathbf{x})]$。

**思路与解答：**

从方程15.8开始，并利用对数性质 $\log(a/b) = \log(a)-\log(b)$：
$L[\boldsymbol{\phi}] = -\int \text{Pr}(\mathbf{x}^*) \log\left[\frac{\text{Pr}(\mathbf{x}^*)}{\text{Pr}(\mathbf{x}^*) + \text{Pr}(\mathbf{x})}\right] d\mathbf{x}^* - \int \text{Pr}(\mathbf{x}) \log\left[\frac{\text{Pr}(\mathbf{x})}{\text{Pr}(\mathbf{x}^*) + \text{Pr}(\mathbf{x})}\right] d\mathbf{x}$
$L[\boldsymbol{\phi}] = -\int \text{Pr}(\mathbf{x}^*) \log\left[\frac{2\text{Pr}(\mathbf{x}^*)/2}{\text{Pr}(\mathbf{x}^*) + \text{Pr}(\mathbf{x})}\right] d\mathbf{x}^* - \dots$
$L[\boldsymbol{\phi}] = -\int \text{Pr}(\mathbf{x}^*) (\log[2\text{Pr}(\mathbf{x}^*)] - \log[\text{Pr}(\mathbf{x}^*)+\text{Pr}(\mathbf{x})]) d\mathbf{x}^* - \dots$
这与 $D_{JS}$ (方程15.9) 的形式非常接近。
$D_{JS} = \frac{1}{2} \int \text{Pr}(\mathbf{x}^*) \log\frac{2\text{Pr}(\mathbf{x}^*)}{\text{Pr}(\mathbf{x}^*)+\text{Pr}(\mathbf{x})} d\mathbf{x}^* + \dots$
$D_{JS} = \frac{1}{2} \left( \int \text{Pr}(\mathbf{x}^*) \log\frac{\text{Pr}(\mathbf{x}^*)}{\dots} d\mathbf{x}^* + \log(2) \int \text{Pr}(\mathbf{x}^*) d\mathbf{x}^* \right) + \dots$
$= \frac{1}{2} (-L[\boldsymbol{\phi}]) + \log(2)$
因此，$L[\boldsymbol{\phi}] = -2 D_{JS}[\text{Pr}(\mathbf{x}^*) || \text{Pr}(\mathbf{x})] + 2 \log(2)$。
(注：这里可能存在常数项的细微差别，但核心关系是线性的。)

**问题 15.3** 考虑用原始形式的线性规划计算推土机距离...写出 $8 \times 16$ 矩阵A的内容。

**思路与解答：**

这是一个线性规划问题设置。
$\mathbf{p}$ 是 $16 \times 1$ 的向量，$\mathbf{p} = [P_{11}, P_{21}, \dots, P_{41}, P_{12}, \dots, P_{44}]^T$。
$\mathbf{b}$ 是 $8 \times 1$ 的向量，$\mathbf{b} = [\text{Pr}(1), \dots, \text{Pr}(4), q(1), \dots, q(4)]^T$。
约束 $\mathbf{Ap} = \mathbf{b}$ 包括：
1.  $\sum_j P_{ij} = \text{Pr}(i)$ for $i=1..4$
2.  $\sum_i P_{ij} = q(j)$ for $j=1..4$
矩阵 $\mathbf{A}$ 是一个 $8 \times 16$ 的矩阵，用来实现这些求和约束。
*   **前4行 (Pr约束)**:
    *   第1行，对应 $\sum_j P_{1j}$: 在 $p$ 中 $P_{11}, P_{12}, P_{13}, P_{14}$ 对应的列为1，其余为0。
    *   第2行，对应 $\sum_j P_{2j}$: 在 $p$ 中 $P_{21}, P_{22}, P_{23}, P_{24}$ 对应的列为1，其余为0。
    *   ... 以此类推。
*   **后4行 (q约束)**:
    *   第5行，对应 $\sum_i P_{i1}$: 在 $p$ 中 $P_{11}, P_{21}, P_{31}, P_{41}$ 对应的列为1，其余为0。
    *   第6行，对应 $\sum_i P_{i2}$: 在 $p$ 中 $P_{12}, P_{22}, P_{32}, P_{42}$ 对应的列为1，其余为0。
    *   ... 以此类推。

**问题 15.4*** 计算两种分布之间的 (i)KL散度, (ii)反向KL散度, (iii)JS散度和 (iv)瓦瑟斯坦距离。

**思路与解答：**

两个分布都是在 $$ 或 $[a, a+1]$ 区间内值为1的均匀分布。
1.  **KL散度 $D_{KL}(P||Q)$**: 如果 $Q(z)=0$ 而 $P(z)>0$ 的地方存在，则KL散度为无穷大。这里两个分布的支撑集（非零区域）在 $a \notin [-1, 1]$ 时不重叠。
    *   当 $a \in (-1, 1)$ 时，有重叠，可以计算积分。
    *   当 $a \le -1$ 或 $a \ge 1$ 时，支撑集不重叠，KL散度为**无穷大**。
2.  **反向KL散度 $D_{KL}(Q||P)$**: 同理，当 $a \le -1$ 或 $a \ge 1$ 时为**无穷大**。
3.  **JS散度**: JS散度总是有限的。它会衡量两个分布的重叠程度。当完全不重叠时（$|a| \ge 1$），JS散度达到最大值 $\log(2)$。
4.  **瓦瑟斯坦距离**: 这是移动质量的成本。
    *   需要移动的总质量是1。
    *   需要移动的平均距离是两个分布均值之差的绝对值。
    *   $P(z)$ 的均值是 0.5。$Q(z)$ 的均值是 $a+0.5$。
    *   瓦瑟斯坦距离 $D_w = |(a+0.5) - 0.5| = |a|$。这个结果非常简洁和直观。

**问题 15.5** KL距离和瓦瑟斯坦距离... 绘制在 $\sigma_1=\sigma_2=1$ 时，它们作为 $\mu_1-\mu_2$ 函数的图像。

**思路与解答：**

当 $\sigma_1=\sigma_2=1$ 时：
*   $D_{KL} = \log(1) + \frac{1 + (\mu_1-\mu_2)^2}{2} - \frac{1}{2} = \frac{1}{2}(\mu_1-\mu_2)^2$。
*   $D_W = (\mu_1-\mu_2)^2 + 1+1 - 2\sqrt{1} = (\mu_1-\mu_2)^2$。
令 $\Delta\mu = \mu_1-\mu_2$。
*   $D_{KL} = \frac{1}{2}(\Delta\mu)^2$ (一个开口向上的抛物线)
*   $D_W = (\Delta\mu)^2$ (一个更陡峭的开口向上的抛物线)
两者都是关于均值差的二次函数，表明均值越远，距离越大。

**问题 15.6** 考虑一个100维的潜变量 $z \sim \mathcal{N}(0, I)$。考虑将该变量的值截断到...标准差。在每种情况下，有多大比例的原始概率分布被忽略了？

**思路与解答：**

截断意味着我们只接受范数 $||\mathbf{z}|| < \tau \sigma_z$ 的样本。对于多维标准正态分布，$\mathbf{z}$ 的范数平方 $||\mathbf{z}||^2 = \sum_{i=1}^{100} z_i^2$ 服从自由度为100的**卡方 ($\chi^2$) 分布**。
标准差 $\sigma_z$ 在这里不适用，我们应该理解为截断到 $\tau$ 个“标准差”的范数半径。这题的表述可能不严谨，我们理解为截断半径 $R = \tau \sqrt{D}$。

一个更简单的方式是考虑每个维度独立。
*   对于一维标准正态分布，落在 $(-\tau, \tau)$ 区间内的概率可以通过误差函数 `erf(τ/√2)` 计算。
*   落在区间外的概率是 $1 - \text{erf}(\tau/\sqrt{2})$。
*   对于100维，所有维度都落在该区间的概率是 $(\text{erf}(\tau/\sqrt{2}))^{100}$。
*   被忽略的比例是 $1 - (\text{erf}(\tau/\sqrt{2}))^{100}$。

计算结果：
*   (i) $\tau=2.0$: 忽略比例 $\approx 1 - (0.9545)^{100} \approx 1 - 0.01 = \mathbf{99\%}$
*   (ii) $\tau=1.0$: 忽略比例 $\approx 1 - (0.6827)^{100} \approx \mathbf{100\%}$
*   (iii) $\tau=0.5$: 忽略比例 $\approx \mathbf{100\%}$
*   (iv) $\tau=0.04$: 忽略比例 $\approx \mathbf{100\%}$

**结论**: 在高维空间中，大部分概率质量都分布在离原点较远的地方（**高维诅咒**）。对范数进行即使是看起来很宽松的截断，也会忽略掉绝大部分的概率分布。